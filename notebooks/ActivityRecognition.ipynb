{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, accuracy_score, recall_score, balanced_accuracy_score, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading, Preprocessing and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33588, 9) in 27 files.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "directory = \"../datasets/Datasets_Healthy_Older_People/S2_Dataset\"\n",
    "cnt = 0\n",
    "train_df = pd.DataFrame()\n",
    "for filename in os.scandir(directory):\n",
    "    while(cnt<27):\n",
    "        df = pd.read_csv(filename, header = None)\n",
    "        cnt+=1\n",
    "        train_df = pd.concat([train_df, df])\n",
    "print(train_df.shape,\"in\", cnt, \"files.\")\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset has no null or object values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(train_df.isnull().sum().sum(), train_df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{dtype('float64'): 7, dtype('int64'): 2}\n"
     ]
    }
   ],
   "source": [
    "list_dtype = [train_df[i].dtype for i in train_df.columns]\n",
    "print(dict((i, list_dtype.count(i)) for i in list_dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8], dtype='int64')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    33237\n",
       "1      216\n",
       "4      135\n",
       "Name: 8, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[8].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_pred = train_df[8].to_numpy()\n",
    "new_pred = []\n",
    "for i in range(len(old_pred)):\n",
    "    if old_pred[i] == 3:\n",
    "        new_pred.append(1)\n",
    "    else:\n",
    "        new_pred.append(0)\n",
    "train_df[8] = new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "i = 8\n",
    "train_df[i] = label_encoder.fit_transform(train_df[i])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    33237\n",
       "0      351\n",
       "Name: 8, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[8].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scl = StandardScaler()\n",
    "scl.fit(train_df)\n",
    "scl.transform(train_df)\n",
    "train_df, test_df = train_test_split(train_df, train_size = 0.9, random_state = 42) \n",
    "y_train = train_df[8]\n",
    "y_test = test_df[8]\n",
    "X_train = train_df.drop([8], axis = 1)\n",
    "X_test = test_df.drop([8], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CentroidSMOTE():\n",
    "    def __init__(self, sampling_strategy='auto', random_state=42, k_neighbors=5, m_vertices=3):\n",
    "        self.sampling_strategy = sampling_strategy\n",
    "        self.random_state = random_state\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.m_vertices = m_vertices\n",
    "    \n",
    "    @staticmethod\n",
    "    def nearest_neighbor(X, k):\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "        nbs=NearestNeighbors(n_neighbors=k+1,metric='euclidean',algorithm='kd_tree').fit(X)\n",
    "        euclidean,indices= nbs.kneighbors(X)\n",
    "        return indices[:, 1:]\n",
    "    \n",
    "    def fit_resample(self, X, y):\n",
    "        \n",
    "        (unique, freq) = np.unique(y, return_counts=True)\n",
    "        frequency = dict(zip(unique, freq))\n",
    "        max_frequency = max(frequency.values())\n",
    "        \n",
    "        if self.sampling_strategy == 'auto':\n",
    "            sampling_strategy = {}\n",
    "            for (key, value) in frequency.items():\n",
    "                sampling_strategy[key] = max_frequency - value\n",
    "            self.sampling_strategy = sampling_strategy\n",
    "            \n",
    "        data = {}\n",
    "        for (key, value) in self.sampling_strategy.items():\n",
    "            if value == 0:\n",
    "                continue\n",
    "            X_small = X[y == key]\n",
    "            indices = self.nearest_neighbor(X_small, self.k_neighbors)\n",
    "            new_data = []\n",
    "            for idx in np.random.choice(np.arange(len(X_small)), size=value):\n",
    "                p = X_small[idx]\n",
    "                nnarray = indices[idx]\n",
    "                q = X_small[np.random.choice(nnarray, size=self.m_vertices-1, replace=False)]\n",
    "                new_data.append(np.sum(np.vstack([p, q]), axis=0)/self.m_vertices)\n",
    "            X_new = np.vstack(new_data)\n",
    "            data[key] = X_new\n",
    "        \n",
    "        for (key, value) in data.items():\n",
    "            X = np.vstack([X, value])\n",
    "            y = np.concatenate([y, np.ones(len(value))*key])\n",
    "        \n",
    "        X, y = shuffle(X, y, random_state=self.random_state)\n",
    "        \n",
    "        return X, y        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(X_test, y_test, model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.6f}\")\n",
    "    print(f\"Error Rate: {1-acc}\")\n",
    "    Recall = recall_score(y_test, y_pred, average='macro')      \n",
    "    print(f\"Mean Recall: {Recall}\")\n",
    "    print(f\"Balanced Accuracy Score: {balanced_accuracy_score(y_test, y_pred)}\")\n",
    "    Array_prec_recall_f = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "#                                                                         average = 'micro', 'macro', 'weighted'\n",
    "    print(f\"Precision: {Array_prec_recall_f[0]}\")\n",
    "    print(f\"F-Score: {Array_prec_recall_f[2]}\")\n",
    "          \n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    print(len(y_pred), len(y_test))\n",
    "    for i in range(len(y_pred)): \n",
    "        if y_test[i]==y_pred[i]==1:\n",
    "           TP += 1\n",
    "        if y_pred[i]==1 and y_test[i]!=y_pred[i]:\n",
    "           FP += 1\n",
    "        if y_test[i]==y_pred[i]==0:\n",
    "           TN += 1\n",
    "        if y_pred[i]==0 and y_test[i]!=y_pred[i]:\n",
    "           FN += 1\n",
    "    if TN + FP == 0: \n",
    "      Selectivity = 0\n",
    "    else:\n",
    "      Selectivity = TN/(TN + FP)\n",
    "    G_mean = np.sqrt(Selectivity*Recall) \n",
    "    print(f\"Selectivity: {Selectivity}\") \n",
    "    print(f\"G_mean: {G_mean}\")   \n",
    "    \n",
    "    \n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
    "\n",
    "    cm_display.plot()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('classifier', KNeighborsClassifier(metric='euclidean'))\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'classifier__n_neighbors' : [3, 5, 7, 9, 11],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(pipeline, param_grid = parameters, cv = 5, verbose=True, n_jobs=-1)\n",
    "best_clf = clf.fit(X_train, y_train)\n",
    "score(X_test, y_test, best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_list = []\n",
    "from collections import Counter\n",
    "for i in [3, 5, 7, 9, 11]:\n",
    "    sm_list.append(SMOTE(random_state=42, k_neighbors=i))\n",
    "for sm in sm_list:\n",
    "    X_new, y_new = sm.fit_resample(X_train, y_train)\n",
    "    print('Resampled dataset shape %s' % Counter(y_new))\n",
    "    pipeline = Pipeline([\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    parameters = {\n",
    "        'classifier__n_neighbors' : [3, 5, 7, 9, 11],\n",
    "    }\n",
    "\n",
    "    clf = GridSearchCV(pipeline, param_grid = parameters, cv = 5, verbose=True, n_jobs=-1)\n",
    "    best_clf = clf.fit(X_new, y_new)\n",
    "    score(X_test, y_test, best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csm_list = []\n",
    "for (i,j) in [(5,3), (7,3), (9,3), (7,5), (9,7)]:\n",
    "    csm_list.append(CentroidSMOTE(k_neighbors=i, m_vertices=j))\n",
    "\n",
    "for csm in csm_list:\n",
    "    X_new, y_new = csm.fit_resample(X_train, y_train)\n",
    "    pipeline = Pipeline([\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ])\n",
    "\n",
    "    parameters = {\n",
    "        'classifier__n_neighbors' : [3, 5, 7, 9, 11],\n",
    "    }\n",
    "\n",
    "    clf = GridSearchCV(pipeline, param_grid = parameters, cv = 5, verbose=True, n_jobs=-1)\n",
    "    best_clf = clf.fit(X_new, y_new)\n",
    "    score(X_test, y_test, best_clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('opencv_real_maker')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bd44383e8a012c0e21c0841592939709362289b3e4024e47beaf9441ea1cb9bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
