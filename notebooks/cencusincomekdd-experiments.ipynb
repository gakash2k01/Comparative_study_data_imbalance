{"cells":[{"cell_type":"code","execution_count":45,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-11-03T17:00:47.870826Z","iopub.status.busy":"2022-11-03T17:00:47.870382Z","iopub.status.idle":"2022-11-03T17:00:47.883950Z","shell.execute_reply":"2022-11-03T17:00:47.882152Z","shell.execute_reply.started":"2022-11-03T17:00:47.870783Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2022-11-03T17:00:47.886844Z","iopub.status.busy":"2022-11-03T17:00:47.886454Z","iopub.status.idle":"2022-11-03T17:00:47.899079Z","shell.execute_reply":"2022-11-03T17:00:47.898047Z","shell.execute_reply.started":"2022-11-03T17:00:47.886806Z"},"trusted":true},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn import metrics\n","from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, accuracy_score, recall_score, balanced_accuracy_score, roc_curve\n","from sklearn.utils import shuffle\n","from sklearn.datasets import make_classification\n","from sklearn.neighbors import NearestNeighbors\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.preprocessing import LabelEncoder\n","\n","from imblearn.over_sampling import SMOTE"]},{"cell_type":"markdown","metadata":{},"source":["# Reading, Preprocessing and EDA"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2022-11-03T17:00:47.913897Z","iopub.status.busy":"2022-11-03T17:00:47.913351Z","iopub.status.idle":"2022-11-03T17:00:50.825474Z","shell.execute_reply":"2022-11-03T17:00:50.824218Z","shell.execute_reply.started":"2022-11-03T17:00:47.913870Z"},"trusted":true},"outputs":[{"ename":"ParserError","evalue":"Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32mc:\\Users\\91735\\Documents\\code_work\\shobhit\\Comparative_study_data_imbalance\\notebooks\\cencusincomekdd-experiments.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/91735/Documents/code_work/shobhit/Comparative_study_data_imbalance/notebooks/cencusincomekdd-experiments.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m Test_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../datasets/cencus_income/census-income.test\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/91735/Documents/code_work/shobhit/Comparative_study_data_imbalance/notebooks/cencusincomekdd-experiments.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(Train_path, header \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/91735/Documents/code_work/shobhit/Comparative_study_data_imbalance/notebooks/cencusincomekdd-experiments.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(Test_path, header \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m)\n","File \u001b[1;32mc:\\Users\\91735\\anaconda3\\envs\\opencv_real_maker\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\91735\\anaconda3\\envs\\opencv_real_maker\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mc:\\Users\\91735\\anaconda3\\envs\\opencv_real_maker\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n","File \u001b[1;32mc:\\Users\\91735\\anaconda3\\envs\\opencv_real_maker\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[0;32m    610\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[1;32m--> 611\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n","File \u001b[1;32mc:\\Users\\91735\\anaconda3\\envs\\opencv_real_maker\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1778\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1771\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[0;32m   1772\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1773\u001b[0m     \u001b[39m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m     (\n\u001b[0;32m   1775\u001b[0m         index,\n\u001b[0;32m   1776\u001b[0m         columns,\n\u001b[0;32m   1777\u001b[0m         col_dict,\n\u001b[1;32m-> 1778\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(  \u001b[39m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1779\u001b[0m         nrows\n\u001b[0;32m   1780\u001b[0m     )\n\u001b[0;32m   1781\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1782\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n","File \u001b[1;32mc:\\Users\\91735\\anaconda3\\envs\\opencv_real_maker\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:230\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[1;32m--> 230\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[0;32m    231\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    232\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n","File \u001b[1;32mc:\\Users\\91735\\anaconda3\\envs\\opencv_real_maker\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:808\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mc:\\Users\\91735\\anaconda3\\envs\\opencv_real_maker\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:866\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mc:\\Users\\91735\\anaconda3\\envs\\opencv_real_maker\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:852\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mc:\\Users\\91735\\anaconda3\\envs\\opencv_real_maker\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1973\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n","\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."]}],"source":["Train_path = \"../datasets/cencus_income/census-income.data\"\n","Test_path = \"../datasets/cencus_income/census-income.test\"\n","train_df = pd.read_csv(Train_path, header = None)\n","test_df = pd.read_csv(Test_path, header = None)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-03T17:00:50.828522Z","iopub.status.busy":"2022-11-03T17:00:50.828030Z","iopub.status.idle":"2022-11-03T17:00:51.295908Z","shell.execute_reply":"2022-11-03T17:00:51.294652Z","shell.execute_reply.started":"2022-11-03T17:00:50.828489Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(199523, 42) (99762, 42)\n"]}],"source":["print(train_df.shape, test_df.shape)"]},{"cell_type":"markdown","metadata":{},"source":["This is our target variable. The income."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-11-03T17:00:51.298557Z","iopub.status.busy":"2022-11-03T17:00:51.297260Z","iopub.status.idle":"2022-11-03T17:00:51.321219Z","shell.execute_reply":"2022-11-03T17:00:51.319831Z","shell.execute_reply.started":"2022-11-03T17:00:51.298483Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" - 50000.    187141\n"," 50000+.      12382\n","Name: 41, dtype: int64  - 50000.    93576\n"," 50000+.      6186\n","Name: 41, dtype: int64\n"]}],"source":["print(train_df[41].value_counts(), test_df[41].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0 0\n"]}],"source":["print(train_df.isnull().sum().sum(), test_df.isna().sum().sum())"]},{"cell_type":"markdown","metadata":{},"source":["It has null values, stored as '?' and has categorical columns too."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{dtype('int64'): 12, dtype('O'): 29, dtype('float64'): 1}\n","{dtype('int64'): 12, dtype('O'): 29, dtype('float64'): 1}\n"]}],"source":["list_dtype = [train_df[i].dtype for i in train_df.columns]\n","print(dict((i, list_dtype.count(i)) for i in list_dtype))\n","\n","list_dtype = [test_df[i].dtype for i in test_df.columns]\n","print(dict((i, list_dtype.count(i)) for i in list_dtype))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" ?\n"]}],"source":["ch = train_df.iloc[11][32]\n","print(ch)\n","train_df = train_df.replace(ch, np.NaN)\n","test_df = test_df.replace(ch, np.NaN)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["21 708\n","25 99696\n","26 99696\n","27 99696\n","29 99696\n","32 6713\n","33 6119\n","34 3393\n","21 330\n","25 49946\n","26 49946\n","27 49946\n","29 49946\n","32 3429\n","33 3072\n","34 1764\n"]}],"source":["null = train_df.isnull().sum()\n","for i in range(len(null)):\n","    if null[i] > 0:\n","        print(i, null[i])\n","\n","null = test_df.isnull().sum()\n","for i in range(len(null)):\n","    if null[i] > 0:\n","        print(i, null[i])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_df = train_df.drop({25, 26, 27, 29}, axis = 1)\n","test_df = test_df.drop({25, 26, 27, 29}, axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["708\n","6713\n","6119\n","3393\n","330\n","3429\n","3072\n","1764\n"]}],"source":["null = train_df.isnull().sum()\n","for i in null:\n","    if i > 0:\n","        print(i)\n","null = test_df.isnull().sum()\n","for i in null:\n","    if i > 0:\n","        print(i)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{dtype('int64'): 12, dtype('O'): 25, dtype('float64'): 1}\n"]}],"source":["list_dtype = [train_df[i].dtype for i in train_df.columns]\n","print(dict((i, list_dtype.count(i)) for i in list_dtype))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for col in train_df.columns:\n","    if 'int' in train_df[col] or 'float' in train_df[col]:\n","        train_df[col] = train_df[col].fillna(train_df[col].mean())\n","        test_df[col] = test_df[col].fillna(train_df[col].mean())\n","    else:\n","        mode_val = train_df[col].mode()[0]\n","        train_df[col] = train_df[col].fillna(mode_val)\n","        test_df[col] = test_df[col].fillna(mode_val)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["null = train_df.isnull().sum()\n","for i in null:\n","    if i > 0:\n","        print(i)\n","\n","null = test_df.isnull().sum()\n","for i in null:\n","    if i > 0:\n","        print(i)"]},{"cell_type":"markdown","metadata":{},"source":["All missing values handled"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" - 50000.    187141\n"," 50000+.      12382\n","Name: 41, dtype: int64  - 50000.    93576\n"," 50000+.      6186\n","Name: 41, dtype: int64\n"]}],"source":["print(train_df[41].value_counts(), test_df[41].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["label_encoder = LabelEncoder()\n","i = 41\n","train_df[i] = label_encoder.fit_transform(train_df[i])    \n","test_df[i] = label_encoder.transform(test_df[i])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0    280717\n","1     18568\n","Name: 41, dtype: int64\n"]}],"source":["combined_df = pd.concat([train_df, test_df])\n","combined_df = pd.get_dummies(combined_df)\n","print(combined_df[i].value_counts())\n","train_df = combined_df[:len(train_df)]\n","test_df = combined_df[len(train_df):]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0    187141\n","1     12382\n","Name: 41, dtype: int64\n","0    93576\n","1     6186\n","Name: 41, dtype: int64\n"]}],"source":["print(train_df[i].value_counts())\n","print(test_df[i].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\91735\\anaconda3\\envs\\opencv_real_maker\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n","  warnings.warn(\n","c:\\Users\\91735\\anaconda3\\envs\\opencv_real_maker\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n","  warnings.warn(\n","c:\\Users\\91735\\anaconda3\\envs\\opencv_real_maker\\lib\\site-packages\\sklearn\\utils\\validation.py:1858: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n","  warnings.warn(\n"]}],"source":["from sklearn.preprocessing import StandardScaler\n","scl = StandardScaler()\n","scl.fit(train_df)\n","scl.transform(train_df)\n","scl.transform(test_df)\n","y_train = train_df[41]\n","y_test = test_df[41]\n","X_train = train_df.drop([41], axis = 1)\n","X_test = test_df.drop([41], axis = 1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class CentroidSMOTE():\n","    def __init__(self, sampling_strategy='auto', random_state=42, k_neighbors=5, m_vertices=3):\n","        self.sampling_strategy = sampling_strategy\n","        self.random_state = random_state\n","        self.k_neighbors = k_neighbors\n","        self.m_vertices = m_vertices\n","    \n","    @staticmethod\n","    def nearest_neighbor(X, k):\n","        from sklearn.neighbors import NearestNeighbors\n","        nbs=NearestNeighbors(n_neighbors=k+1,metric='euclidean',algorithm='kd_tree').fit(X)\n","        euclidean,indices= nbs.kneighbors(X)\n","        return indices[:, 1:]\n","    \n","    def fit_resample(self, X, y):\n","        \n","        (unique, freq) = np.unique(y, return_counts=True)\n","        frequency = dict(zip(unique, freq))\n","        max_frequency = max(frequency.values())\n","        \n","        if self.sampling_strategy == 'auto':\n","            sampling_strategy = {}\n","            for (key, value) in frequency.items():\n","                sampling_strategy[key] = max_frequency - value\n","            self.sampling_strategy = sampling_strategy\n","            \n","        data = {}\n","        for (key, value) in self.sampling_strategy.items():\n","            if value == 0:\n","                continue\n","            X_small = X[y == key]\n","            indices = self.nearest_neighbor(X_small, self.k_neighbors)\n","            new_data = []\n","            for idx in np.random.choice(np.arange(len(X_small)), size=value):\n","                p = X_small[idx]\n","                nnarray = indices[idx]\n","                q = X_small[np.random.choice(nnarray, size=self.m_vertices-1, replace=False)]\n","                new_data.append(np.sum(np.vstack([p, q]), axis=0)/self.m_vertices)\n","            X_new = np.vstack(new_data)\n","            data[key] = X_new\n","        \n","        for (key, value) in data.items():\n","            X = np.vstack([X, value])\n","            y = np.concatenate([y, np.ones(len(value))*key])\n","        \n","        X, y = shuffle(X, y, random_state=self.random_state)\n","        \n","        return X, y        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def score(X_test, y_test, model):\n","    y_pred = model.predict(X_test)\n","    acc = accuracy_score(y_test, y_pred)\n","    \n","    print(f\"Accuracy: {acc:.6f}\")\n","    print(f\"Error Rate: {1-acc}\")\n","    Recall = recall_score(y_test, y_pred, average='macro')      \n","    print(f\"Mean Recall: {Recall}\")\n","    print(f\"Balanced Accuracy Score: {balanced_accuracy_score(y_test, y_pred)}\")\n","    Array_prec_recall_f = precision_recall_fscore_support(y_test, y_pred, average='macro')\n","#                                                                         average = 'micro', 'macro', 'weighted'\n","    print(f\"Precision: {Array_prec_recall_f[0]}\")\n","    print(f\"F-Score: {Array_prec_recall_f[2]}\")\n","          \n","    \n","    TP = 0\n","    FP = 0\n","    TN = 0\n","    FN = 0\n","    print(len(y_pred), len(y_test))\n","    for i in range(len(y_pred)): \n","        if y_test[i]==y_pred[i]==1:\n","           TP += 1\n","        if y_pred[i]==1 and y_test[i]!=y_pred[i]:\n","           FP += 1\n","        if y_test[i]==y_pred[i]==0:\n","           TN += 1\n","        if y_pred[i]==0 and y_test[i]!=y_pred[i]:\n","           FN += 1\n","    if TN + FP == 0: \n","      Selectivity = 0\n","    else:\n","      Selectivity = TN/(TN + FP)\n","    G_mean = np.sqrt(Selectivity*Recall) \n","    print(f\"Selectivity: {Selectivity}\") \n","    print(f\"G_mean: {G_mean}\")   \n","    \n","    \n","    confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n","\n","    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n","\n","    cm_display.plot()\n","    plt.show()\n","    \n","    \n","    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n","    plt.plot(fpr, tpr)\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","   \n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pipeline = Pipeline([\n","    ('classifier', KNeighborsClassifier(metric='euclidean'))\n","])\n","\n","parameters = {\n","    'classifier__n_neighbors' : [3, 5, 7, 9, 11],\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["y_test = y_test.to_numpy()\n","y_train = y_train.to_numpy()\n","X_train = X_train.to_numpy()\n","X_test = X_test.to_numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["clf = GridSearchCV(pipeline, param_grid = parameters, cv = 5, verbose=True, n_jobs=-1)\n","best_clf = clf.fit(X_train, y_train)\n","score(X_test, y_test, best_clf)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sm_list = []\n","from collections import Counter\n","for i in [3, 5, 7, 9, 11]:\n","    sm_list.append(SMOTE(random_state=42, k_neighbors=i))\n","for sm in sm_list:\n","    X_new, y_new = sm.fit_resample(X_train, y_train)\n","    print('Resampled dataset shape %s' % Counter(y_new))\n","    pipeline = Pipeline([\n","        ('classifier', KNeighborsClassifier())\n","    ])\n","\n","    parameters = {\n","        'classifier__n_neighbors' : [3, 5, 7, 9, 11],\n","    }\n","\n","    clf = GridSearchCV(pipeline, param_grid = parameters, cv = 5, verbose=True, n_jobs=-1)\n","    best_clf = clf.fit(X_new, y_new)\n","    score(X_test, y_test, best_clf)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["csm_list = []\n","for (i,j) in [(5,3), (7,3), (9,3), (7,5), (9,7)]:\n","    csm_list.append(CentroidSMOTE(k_neighbors=i, m_vertices=j))\n","\n","for csm in csm_list:\n","    X_new, y_new = csm.fit_resample(X_train, y_train)\n","    pipeline = Pipeline([\n","        ('classifier', KNeighborsClassifier())\n","    ])\n","\n","    parameters = {\n","        'classifier__n_neighbors' : [3, 5, 7, 9, 11],\n","    }\n","\n","    clf = GridSearchCV(pipeline, param_grid = parameters, cv = 5, verbose=True, n_jobs=-1)\n","    best_clf = clf.fit(X_new, y_new)\n","    score(X_test, y_test, best_clf)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.13 ('opencv_real_maker')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"bd44383e8a012c0e21c0841592939709362289b3e4024e47beaf9441ea1cb9bc"}}},"nbformat":4,"nbformat_minor":4}
